{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kevin-1001/Deep_Learning_With_Computer_Vision/blob/main/Copy_of_DL4CV_Prog_Assignment_2_Week_3_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Welcome to Assignment 3 on Deep Learning for Computer Vision.**\n",
        "This assignment is based on the content you learned in Week-3.\n",
        "\n",
        "#### **Instructions**\n",
        "1. Use Python 3.x to run this notebook\n",
        "2. Write your code only in between the lines 'YOUR CODE STARTS HERE' and 'YOUR CODE ENDS HERE'. You should not change anything else in the code cells, if you do, the answers you are supposed to get at the end of this assignment might be wrong.\n",
        "3. Read documentation of each function carefully.\n",
        "4. All the Best!"
      ],
      "metadata": {
        "id": "NmJM6wJJBA0-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch operations"
      ],
      "metadata": {
        "id": "Hoc9we-EBPNz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will perform basic elementwise operations between two matrices\n",
        "\n",
        "Step1: rearrange the give input x into a tensor of shape (10,5,3) and store it in variable x_resize \\\\\n",
        "Step2: Generate a gaussian random tensor (mean =0, variance=1) of shape (5,3) and store it in variable y1 \\\\\n",
        "Step3:  Generate a uniform random tensor (interval [-10,10)) of shape (5,3) and store it in variable y2 \\\\\n",
        "Step4: Perform elementwise multiplication between x_resize and y1, store it in variable mul_output1 \\\\\n",
        "Step5: Find the max element along the last dimension of mul_output1 and store its value in final_output1 \\\\\n",
        "Step6: Repeat Step4 and Step5 for x_resize and y2 and store the corresponding values in the variables, mul_output2 and final_output2."
      ],
      "metadata": {
        "id": "JWfSxU7fBQJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# DO NOT CHANGE THE SEED\n",
        "torch.manual_seed(2)\n",
        "\n",
        "x = torch.randint(low=0, high=256, size=(1, 150))\n",
        "\n",
        "### YOUR CODE STARTS HERE ###\n",
        "\n",
        "# Step 1: Reshape x into a tensor of shape (10, 5, 3)\n",
        "x_resize = x.view(10, 5, 3)\n",
        "\n",
        "# Step 2: Generate a Gaussian random tensor of shape (5, 3)\n",
        "y1 = torch.randn(5, 3)\n",
        "\n",
        "# Step 3: Generate a uniform random tensor of shape (5, 3)\n",
        "y2 = torch.rand(5, 3) * 20 - 10  # Scale to the range [-10, 10)\n",
        "\n",
        "# Step 4: Elementwise multiplication between x_resize and y1\n",
        "mul_output1 = x_resize * y1\n",
        "\n",
        "# Step 5: Find the max element along the last dimension of mul_output1\n",
        "final_output1, _ = torch.max(mul_output1, dim=2)\n",
        "\n",
        "# Step 6: Repeat for y2\n",
        "mul_output2 = x_resize * y2\n",
        "final_output2, _ = torch.max(mul_output2, dim=2)\n",
        "\n",
        "### YOUR CODE ENDS HERE ###\n",
        "\n",
        "# Calculate the mean of the sum of final_output1 and final_output2\n",
        "print(torch.mean(final_output1 + final_output2))\n"
      ],
      "metadata": {
        "id": "V1T3yhVcBAQE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "164f3dc4-6d85-4e5b-8b3a-3d136aff9f5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(879.7391)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1. What is mean of the sum of final_output1 and final_output2? (Select the closest value)\n",
        "\n",
        "a) 875\n",
        "\n",
        "b) 880\n",
        "\n",
        "c) 883\n",
        "\n",
        "d) 870\n"
      ],
      "metadata": {
        "id": "S3J0KYReBhS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 880"
      ],
      "metadata": {
        "id": "TrVEf2wKNVyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom loss function and its Gradients"
      ],
      "metadata": {
        "id": "LoZ1CgxhGqXu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this we will implement a custom loss function and calculate the gradient of this loss function w.r.t two input tensors.\n",
        "\n",
        "The loss function takes two inputs, y_true (given) and y_pred. Follow the below step to generate y_pred.\n",
        "\n",
        "1) Calculate the matrix-vector multiplication between 'M' and 'v' and store it in the variable \"y_pred\".\n"
      ],
      "metadata": {
        "id": "U2E-g_zVFfxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# DO NOT CHANGE THE SEED\n",
        "torch.manual_seed(0)\n",
        "\n",
        "y_true = torch.tensor([0.3, 0.7, 0.6])\n",
        "\n",
        "m, n = 3, 2\n",
        "M = torch.randn(m, n, requires_grad=True)\n",
        "v = torch.randn(n, requires_grad=True)\n",
        "\n",
        "### YOUR CODE STARTS HERE ###\n",
        "# Step 1: Calculate the matrix-vector multiplication between 'M' and 'v'\n",
        "y_pred = torch.matmul(M, v)\n",
        "### YOUR CODE ENDS HERE ###\n",
        "\n",
        "# Print y_pred to verify the result\n",
        "print(y_pred)\n"
      ],
      "metadata": {
        "id": "fBABuqJbQpa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29ef7604-0597-4044-ef22-a976814319e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.3757, -0.4024, -1.6095], grad_fn=<MvBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, implement a custom loss function in PyTorch that computes the mean squared error (MSE) between two tensors (y_true, y_pred), but only for elements where the target tensor y_true is greater than 0.5. Save the calculated MSE loss in a variable named \"loss\".\n",
        "\n",
        "*(Hint: First create a mask on y_true and then multiply the mask with the loss)*"
      ],
      "metadata": {
        "id": "Ptu_2jENQ0E2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# DO NOT CHANGE THE SEED\n",
        "torch.manual_seed(0)\n",
        "\n",
        "class CustomMSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomMSELoss, self).__init__()\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        ### YOUR CODE STARTS HERE ###\n",
        "        # Step 1: Create a mask where y_true > 0.5\n",
        "        mask = (y_true > 0.5).float()\n",
        "\n",
        "        # Step 2: Compute the squared differences\n",
        "        squared_diff = (y_pred - y_true) ** 2\n",
        "\n",
        "        # Step 3: Apply the mask\n",
        "        masked_squared_diff = squared_diff * mask\n",
        "\n",
        "        # Step 4: Calculate the loss (sum of masked_squared_diff divided by the count of elements where y_true > 0.5)\n",
        "        loss = masked_squared_diff.sum() / mask.sum()\n",
        "        ### YOUR CODE ENDS HERE ###\n",
        "\n",
        "        return loss\n",
        "\n",
        "### DO NOT CHANGE ###\n",
        "loss_fn = CustomMSELoss()\n",
        "loss = loss_fn(y_pred, y_true)\n",
        "print(\"Loss: \", loss)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "#DO NOT CHANGE THE SEED\n",
        "torch.manual_seed(0)\n",
        "\n",
        "class CustomMSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomMSELoss, self).__init__()\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        ### YOUR CODE STARTS HERE ###\n",
        "        mask = y_true > 0.5  # Create a mask for elements where y_true > 0.5\n",
        "        squared_diff = (y_pred - y_true)**2  # Calculate squared difference\n",
        "        masked_squared_diff = squared_diff * mask  # Apply the mask\n",
        "\n",
        "        # For calculating the mean, take the sum of masked_squared_diff and divide by the number of elements in the mask\n",
        "        loss = torch.sum(masked_squared_diff) / torch.sum(mask)\n",
        "        ### YOUR CODE ENDS HERE ###\n",
        "        return loss\n",
        "\n",
        "### DO NOT CHANGE ###\n",
        "loss_fn = CustomMSELoss()\n",
        "loss = loss_fn(y_pred, y_true)\n",
        "print(\"Loss: \", loss)\n"
      ],
      "metadata": {
        "id": "JXQ-8VUAFbg3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d711827-de18-40d7-b9cd-ac46ca81a008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(3.0486, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, calculate the gradient of the loss w.r.t tensors M and v.\n",
        "\n",
        "Store the gradient w.r.t M in a variable grad_M\n",
        "\n",
        "Store the gradient w.r.t v in a variable grad_v\n",
        "\n",
        "(Hint: Look into the autograd library of Pytorch. https://pytorch.org/docs/stable/generated/torch.autograd.grad.html)\n"
      ],
      "metadata": {
        "id": "yobH-28VSj6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "# DO NOT CHANGE THE SEED\n",
        "torch.manual_seed(2)\n",
        "\n",
        "class MultiLayerNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MultiLayerNN, self).__init__()\n",
        "        ### YOUR CODE STARTS HERE ###\n",
        "        self.fc1 = nn.Linear(10, 20)\n",
        "        self.fc2 = nn.Linear(20, 50)\n",
        "        self.fc3 = nn.Linear(50, 5)\n",
        "        ### YOUR CODE ENDS HERE ###\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### YOUR CODE STARTS HERE ###\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        ### YOUR CODE ENDS HERE ###\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# DO NOT CHANGE:\n",
        "model = MultiLayerNN()\n",
        "input_tensor = torch.randn(32, 10)\n",
        "output = model(input_tensor)\n",
        "print(\"Mean of the output: \", output.mean() * 1000)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "#DO NOT CHANGE THE SEED\n",
        "torch.manual_seed(0)\n",
        "\n",
        "class CustomMSELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomMSELoss, self).__init__()\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        mask = y_true > 0.5  # Create a mask for elements where y_true > 0.5\n",
        "        squared_diff = (y_pred - y_true)**2  # Calculate squared difference\n",
        "        masked_squared_diff = squared_diff * mask  # Apply the mask\n",
        "\n",
        "        # For calculating the mean, take the sum of masked_squared_diff and divide by the number of elements in the mask\n",
        "        loss = torch.sum(masked_squared_diff) / torch.sum(mask)\n",
        "        return loss\n",
        "\n",
        "### DO NOT CHANGE ###\n",
        "loss_fn = CustomMSELoss()\n",
        "loss = loss_fn(y_pred, y_true)\n",
        "print(\"Loss: \", loss)\n",
        "\n",
        "\n",
        "### DO NOT CHANGE ###\n",
        "# Compute gradients using autograd\n",
        "loss.backward()  # This computes gradients for all tensors that have requires_grad=True\n",
        "\n",
        "### YOUR CODE STARTS HERE ###\n",
        "grad_M = M.grad\n",
        "grad_v = v.grad\n",
        "### YOUR CODE ENDS HERE ###\n",
        "\n",
        "print(\"Sum of Gradient Means: \", grad_M.mean()+grad_v.mean())\n"
      ],
      "metadata": {
        "id": "mJ32T1UKGIG1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d30c0f0-d9a4-44ec-a731-ff84828c8c0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss:  tensor(3.0486, grad_fn=<DivBackward0>)\n",
            "Sum of Gradient Means:  tensor(2.9457)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 2: What is the loss value calculated using the Custom Loss function? (Select the closest value)\n",
        "\n",
        "a) 1\n",
        "\n",
        "b) 2.5\n",
        "\n",
        "c)1.5\n",
        "\n",
        "d) 2\n",
        "\n"
      ],
      "metadata": {
        "id": "fvfiNAByIeXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#2.5"
      ],
      "metadata": {
        "id": "h9ZJdeaiHnt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 3: What is sum of the means of the gradients, grad_M and grad_v? (Select the closest value)\n",
        "\n",
        "a) 2\n",
        "\n",
        "b) 1.7\n",
        "\n",
        "c) 2.5\n",
        "\n",
        "d) 3\n",
        "\n"
      ],
      "metadata": {
        "id": "aqCl_hozIznS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#3"
      ],
      "metadata": {
        "id": "1T4QU3Z9IZM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi Layer Perceptron"
      ],
      "metadata": {
        "id": "4P4t0PvQOpVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this, we will implement a simple multilayer feedforward neural network using PyTorch with the following specifications:\n",
        "\n",
        "Input dimension: 10\n",
        "\n",
        "Hidden layer 1 dimension: 20\n",
        "\n",
        "Hidden layer 2 dimension:  50\n",
        "\n",
        "Output dimension: 5\n",
        "\n",
        "Activation function: ReLU for the hidden layer\n",
        "\n",
        "Your function should take a tensor x of shape (batch_size, 10) as input and return the output of the neural network."
      ],
      "metadata": {
        "id": "mMRqbxxrFUkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "#DO NOT CHANGE THE SEED\n",
        "torch.manual_seed(2)\n",
        "\n",
        "# Define the multi-layer neural network class\n",
        "class MultiLayerNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MultiLayerNN, self).__init__()\n",
        "\n",
        "        ### YOUR CODE STARTS HERE ###\n",
        "        self.fc1 = ___ # Input layer to first hidden layer\n",
        "        self.fc2 = ___  # First hidden layer to second hidden layer\n",
        "        self.fc3 = ___   # Second hidden layer to output layer\n",
        "        ### YOUR CODE ENDS HERE ###\n",
        "\n",
        "    def forward(self, x):\n",
        "       ### YOUR CODE STARTS HERE ###\n",
        "        x = ___\n",
        "        x = ___\n",
        "\n",
        "        ### YOUR CODE ENDS HERE ###\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# DO NOT CHANGE:\n",
        "model = MultiLayerNN()\n",
        "input_tensor = torch.randn(32, 10)\n",
        "output = model(input_tensor)\n",
        "print(\"Mean of the output: \",output.mean()*1000)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "#DO NOT CHANGE THE SEED\n",
        "torch.manual_seed(2)\n",
        "\n",
        "# Define the multi-layer neural network class\n",
        "class MultiLayerNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MultiLayerNN, self).__init__()\n",
        "\n",
        "        ### YOUR CODE STARTS HERE ###\n",
        "        self.fc1 = nn.Linear(10, 20)  # Input layer to first hidden layer\n",
        "        self.fc2 = nn.Linear(20, 50)  # First hidden layer to second hidden layer\n",
        "        self.fc3 = nn.Linear(50, 5)  # Second hidden layer to output layer\n",
        "        ### YOUR CODE ENDS HERE ###\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### YOUR CODE STARTS HERE ###\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "\n",
        "        ### YOUR CODE ENDS HERE ###\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# DO NOT CHANGE:\n",
        "model = MultiLayerNN()\n",
        "input_tensor = torch.randn(32, 10)\n",
        "output = model(input_tensor)\n",
        "print(\"Mean of the output: \",output.mean()*1000)\n"
      ],
      "metadata": {
        "id": "Wobrcv22KoFZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdf85a3c-96cd-4477-bfc1-93cd552e2ae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean of the output:  tensor(1.8321, grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 4: What is mean of the output? (Select the closest value)\n",
        "\n",
        "a) 1.6\n",
        "\n",
        "b) 2.2\n",
        "\n",
        "c) 3\n",
        "\n",
        "d) 1.8\n",
        "\n"
      ],
      "metadata": {
        "id": "J2vd3u7qO-jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1.8"
      ],
      "metadata": {
        "id": "2v01ou_lI6YK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "# ... (rest of the code)\n",
        "\n",
        "# Create train and test TensorDatasets from the respective numpy arrays\n",
        "\n",
        "#### YOUR CODE STARTS HERE ####\n",
        "\n",
        "train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
        "test_dataset = torch.utils.data.TensorDataset(x_test, y_test)\n",
        "\n",
        "#### YOUR CODE ENDS HERE ####\n",
        "\n",
        "# Create dataloaders using the datasets created in the previous cell.\n",
        "# Use a batch size of 64\n",
        "\n",
        "#### YOUR CODE STARTS HERE ####\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "#### YOUR CODE ENDS HERE ####\n",
        "\n",
        "\n",
        "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "        #### YOUR CODE STARTS HERE ####\n",
        "\n",
        "        # send the data, target to the device\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        # flush out the gradients stored in optimizer\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # pass the batch to the model and assign the output to variable named y_pred\n",
        "        output = model(data)\n",
        "\n",
        "        # calculate the loss (use CrossEntropyLoss in pytorch)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # do a backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # update the weights\n",
        "        optimizer.step()\n",
        "\n",
        "        #### YOUR CODE ENDS HERE ####\n",
        "\n",
        "        # Store loss\n",
        "        epoch_loss += loss.item() * data.shape[0]\n",
        "\n",
        "    print(f\"Train Average Loss: {epoch_loss/len(train_loader.dataset):.2f}\")\n",
        "\n",
        "\n",
        "def test(model, device, test_loader, criterion, mode):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            #### YOUR CODE STARTS HERE ####\n",
        "\n",
        "            # send data, target to the device\n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            # pass the image to the model and assign the output to variable named output\n",
        "            output = model(data)\n",
        "            #### YOUR CODE ENDS HERE ####\n",
        "\n",
        "            test_loss += criterion(output, target).item() * data.shape[0]  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_acc = 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "    print(f\"{mode} Average loss: {test_loss:.2f}\")\n",
        "    print(f\"{mode} Accuracy: {correct}/{len(test_loader.dataset)} ({test_acc:.2f}%)\")\n",
        "\n",
        "\n",
        "set_seed(2022)\n",
        "\n",
        "num_epochs = 300\n",
        "\n",
        "#### YOUR CODE STARTS HERE ####\n",
        "\n",
        "# check availability of GPU and set the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize MLP model\n",
        "model = MultiLayerNN().to(device)\n",
        "\n",
        "# Define Adam Optimizer with a learning rate of 0.001\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Define CrossEntropyLoss as the criterion\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#### YOUR CODE ENDS HERE ####\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    print(f\"\\nEpoch: {epoch}/{num_epochs}\")\n",
        "\n",
        "    train(model, device, train_loader, optimizer, criterion, epoch)\n",
        "    test(model, device, test_loader, criterion, mode=\"Test\")\n",
        "\n",
        "\n",
        "test(model, device, train_loader, criterion, mode=\"Train\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpxsHW6FJ3il",
        "outputId": "6fb6d9c3-4bf0-47f6-c42f-3118430ffd89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1/300\n",
            "Train Average Loss: 1.61\n",
            "Test Average loss: 1.62\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 2/300\n",
            "Train Average Loss: 1.61\n",
            "Test Average loss: 1.62\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 3/300\n",
            "Train Average Loss: 1.61\n",
            "Test Average loss: 1.62\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 4/300\n",
            "Train Average Loss: 1.61\n",
            "Test Average loss: 1.62\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 5/300\n",
            "Train Average Loss: 1.61\n",
            "Test Average loss: 1.62\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 6/300\n",
            "Train Average Loss: 1.61\n",
            "Test Average loss: 1.62\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 7/300\n",
            "Train Average Loss: 1.61\n",
            "Test Average loss: 1.62\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 8/300\n",
            "Train Average Loss: 1.61\n",
            "Test Average loss: 1.62\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 9/300\n",
            "Train Average Loss: 1.60\n",
            "Test Average loss: 1.62\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 10/300\n",
            "Train Average Loss: 1.60\n",
            "Test Average loss: 1.62\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 11/300\n",
            "Train Average Loss: 1.60\n",
            "Test Average loss: 1.62\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 12/300\n",
            "Train Average Loss: 1.60\n",
            "Test Average loss: 1.62\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 13/300\n",
            "Train Average Loss: 1.60\n",
            "Test Average loss: 1.62\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 14/300\n",
            "Train Average Loss: 1.60\n",
            "Test Average loss: 1.63\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 15/300\n",
            "Train Average Loss: 1.60\n",
            "Test Average loss: 1.63\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 16/300\n",
            "Train Average Loss: 1.60\n",
            "Test Average loss: 1.63\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 17/300\n",
            "Train Average Loss: 1.60\n",
            "Test Average loss: 1.63\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 18/300\n",
            "Train Average Loss: 1.59\n",
            "Test Average loss: 1.63\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 19/300\n",
            "Train Average Loss: 1.59\n",
            "Test Average loss: 1.63\n",
            "Test Accuracy: 7/30 (23.33%)\n",
            "\n",
            "Epoch: 20/300\n",
            "Train Average Loss: 1.59\n",
            "Test Average loss: 1.63\n",
            "Test Accuracy: 7/30 (23.33%)\n",
            "\n",
            "Epoch: 21/300\n",
            "Train Average Loss: 1.59\n",
            "Test Average loss: 1.64\n",
            "Test Accuracy: 8/30 (26.67%)\n",
            "\n",
            "Epoch: 22/300\n",
            "Train Average Loss: 1.59\n",
            "Test Average loss: 1.64\n",
            "Test Accuracy: 7/30 (23.33%)\n",
            "\n",
            "Epoch: 23/300\n",
            "Train Average Loss: 1.59\n",
            "Test Average loss: 1.64\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 24/300\n",
            "Train Average Loss: 1.59\n",
            "Test Average loss: 1.64\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 25/300\n",
            "Train Average Loss: 1.59\n",
            "Test Average loss: 1.64\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 26/300\n",
            "Train Average Loss: 1.58\n",
            "Test Average loss: 1.65\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 27/300\n",
            "Train Average Loss: 1.58\n",
            "Test Average loss: 1.65\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 28/300\n",
            "Train Average Loss: 1.58\n",
            "Test Average loss: 1.65\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 29/300\n",
            "Train Average Loss: 1.58\n",
            "Test Average loss: 1.65\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 30/300\n",
            "Train Average Loss: 1.58\n",
            "Test Average loss: 1.65\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 31/300\n",
            "Train Average Loss: 1.58\n",
            "Test Average loss: 1.65\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 32/300\n",
            "Train Average Loss: 1.58\n",
            "Test Average loss: 1.65\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 33/300\n",
            "Train Average Loss: 1.58\n",
            "Test Average loss: 1.65\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 34/300\n",
            "Train Average Loss: 1.57\n",
            "Test Average loss: 1.66\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 35/300\n",
            "Train Average Loss: 1.57\n",
            "Test Average loss: 1.66\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 36/300\n",
            "Train Average Loss: 1.57\n",
            "Test Average loss: 1.66\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 37/300\n",
            "Train Average Loss: 1.57\n",
            "Test Average loss: 1.67\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 38/300\n",
            "Train Average Loss: 1.57\n",
            "Test Average loss: 1.67\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 39/300\n",
            "Train Average Loss: 1.57\n",
            "Test Average loss: 1.68\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 40/300\n",
            "Train Average Loss: 1.57\n",
            "Test Average loss: 1.68\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 41/300\n",
            "Train Average Loss: 1.57\n",
            "Test Average loss: 1.68\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 42/300\n",
            "Train Average Loss: 1.57\n",
            "Test Average loss: 1.68\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 43/300\n",
            "Train Average Loss: 1.57\n",
            "Test Average loss: 1.68\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 44/300\n",
            "Train Average Loss: 1.56\n",
            "Test Average loss: 1.68\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 45/300\n",
            "Train Average Loss: 1.56\n",
            "Test Average loss: 1.68\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 46/300\n",
            "Train Average Loss: 1.56\n",
            "Test Average loss: 1.68\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 47/300\n",
            "Train Average Loss: 1.56\n",
            "Test Average loss: 1.68\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 48/300\n",
            "Train Average Loss: 1.56\n",
            "Test Average loss: 1.67\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 49/300\n",
            "Train Average Loss: 1.56\n",
            "Test Average loss: 1.67\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 50/300\n",
            "Train Average Loss: 1.56\n",
            "Test Average loss: 1.67\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 51/300\n",
            "Train Average Loss: 1.56\n",
            "Test Average loss: 1.67\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 52/300\n",
            "Train Average Loss: 1.56\n",
            "Test Average loss: 1.67\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 53/300\n",
            "Train Average Loss: 1.56\n",
            "Test Average loss: 1.67\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 54/300\n",
            "Train Average Loss: 1.56\n",
            "Test Average loss: 1.67\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 55/300\n",
            "Train Average Loss: 1.56\n",
            "Test Average loss: 1.68\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 56/300\n",
            "Train Average Loss: 1.56\n",
            "Test Average loss: 1.68\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 57/300\n",
            "Train Average Loss: 1.55\n",
            "Test Average loss: 1.68\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 58/300\n",
            "Train Average Loss: 1.55\n",
            "Test Average loss: 1.68\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 59/300\n",
            "Train Average Loss: 1.55\n",
            "Test Average loss: 1.68\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 60/300\n",
            "Train Average Loss: 1.55\n",
            "Test Average loss: 1.68\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 61/300\n",
            "Train Average Loss: 1.55\n",
            "Test Average loss: 1.68\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 62/300\n",
            "Train Average Loss: 1.55\n",
            "Test Average loss: 1.69\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 63/300\n",
            "Train Average Loss: 1.55\n",
            "Test Average loss: 1.69\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 64/300\n",
            "Train Average Loss: 1.55\n",
            "Test Average loss: 1.69\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 65/300\n",
            "Train Average Loss: 1.54\n",
            "Test Average loss: 1.69\n",
            "Test Accuracy: 3/30 (10.00%)\n",
            "\n",
            "Epoch: 66/300\n",
            "Train Average Loss: 1.54\n",
            "Test Average loss: 1.69\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 67/300\n",
            "Train Average Loss: 1.54\n",
            "Test Average loss: 1.68\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 68/300\n",
            "Train Average Loss: 1.54\n",
            "Test Average loss: 1.68\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 69/300\n",
            "Train Average Loss: 1.54\n",
            "Test Average loss: 1.68\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 70/300\n",
            "Train Average Loss: 1.54\n",
            "Test Average loss: 1.68\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 71/300\n",
            "Train Average Loss: 1.54\n",
            "Test Average loss: 1.69\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 72/300\n",
            "Train Average Loss: 1.54\n",
            "Test Average loss: 1.69\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 73/300\n",
            "Train Average Loss: 1.53\n",
            "Test Average loss: 1.69\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 74/300\n",
            "Train Average Loss: 1.53\n",
            "Test Average loss: 1.69\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 75/300\n",
            "Train Average Loss: 1.53\n",
            "Test Average loss: 1.69\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 76/300\n",
            "Train Average Loss: 1.53\n",
            "Test Average loss: 1.70\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 77/300\n",
            "Train Average Loss: 1.53\n",
            "Test Average loss: 1.70\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 78/300\n",
            "Train Average Loss: 1.53\n",
            "Test Average loss: 1.70\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 79/300\n",
            "Train Average Loss: 1.53\n",
            "Test Average loss: 1.71\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 80/300\n",
            "Train Average Loss: 1.53\n",
            "Test Average loss: 1.71\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 81/300\n",
            "Train Average Loss: 1.52\n",
            "Test Average loss: 1.71\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 82/300\n",
            "Train Average Loss: 1.52\n",
            "Test Average loss: 1.71\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 83/300\n",
            "Train Average Loss: 1.52\n",
            "Test Average loss: 1.71\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 84/300\n",
            "Train Average Loss: 1.52\n",
            "Test Average loss: 1.71\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 85/300\n",
            "Train Average Loss: 1.52\n",
            "Test Average loss: 1.71\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 86/300\n",
            "Train Average Loss: 1.52\n",
            "Test Average loss: 1.71\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 87/300\n",
            "Train Average Loss: 1.52\n",
            "Test Average loss: 1.71\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 88/300\n",
            "Train Average Loss: 1.52\n",
            "Test Average loss: 1.70\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 89/300\n",
            "Train Average Loss: 1.51\n",
            "Test Average loss: 1.70\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 90/300\n",
            "Train Average Loss: 1.51\n",
            "Test Average loss: 1.70\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 91/300\n",
            "Train Average Loss: 1.51\n",
            "Test Average loss: 1.70\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 92/300\n",
            "Train Average Loss: 1.51\n",
            "Test Average loss: 1.70\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 93/300\n",
            "Train Average Loss: 1.51\n",
            "Test Average loss: 1.70\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 94/300\n",
            "Train Average Loss: 1.51\n",
            "Test Average loss: 1.70\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 95/300\n",
            "Train Average Loss: 1.51\n",
            "Test Average loss: 1.69\n",
            "Test Accuracy: 7/30 (23.33%)\n",
            "\n",
            "Epoch: 96/300\n",
            "Train Average Loss: 1.51\n",
            "Test Average loss: 1.69\n",
            "Test Accuracy: 7/30 (23.33%)\n",
            "\n",
            "Epoch: 97/300\n",
            "Train Average Loss: 1.51\n",
            "Test Average loss: 1.69\n",
            "Test Accuracy: 7/30 (23.33%)\n",
            "\n",
            "Epoch: 98/300\n",
            "Train Average Loss: 1.51\n",
            "Test Average loss: 1.69\n",
            "Test Accuracy: 7/30 (23.33%)\n",
            "\n",
            "Epoch: 99/300\n",
            "Train Average Loss: 1.51\n",
            "Test Average loss: 1.69\n",
            "Test Accuracy: 7/30 (23.33%)\n",
            "\n",
            "Epoch: 100/300\n",
            "Train Average Loss: 1.50\n",
            "Test Average loss: 1.69\n",
            "Test Accuracy: 7/30 (23.33%)\n",
            "\n",
            "Epoch: 101/300\n",
            "Train Average Loss: 1.50\n",
            "Test Average loss: 1.69\n",
            "Test Accuracy: 7/30 (23.33%)\n",
            "\n",
            "Epoch: 102/300\n",
            "Train Average Loss: 1.50\n",
            "Test Average loss: 1.69\n",
            "Test Accuracy: 7/30 (23.33%)\n",
            "\n",
            "Epoch: 103/300\n",
            "Train Average Loss: 1.50\n",
            "Test Average loss: 1.69\n",
            "Test Accuracy: 7/30 (23.33%)\n",
            "\n",
            "Epoch: 104/300\n",
            "Train Average Loss: 1.50\n",
            "Test Average loss: 1.70\n",
            "Test Accuracy: 7/30 (23.33%)\n",
            "\n",
            "Epoch: 105/300\n",
            "Train Average Loss: 1.50\n",
            "Test Average loss: 1.70\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 106/300\n",
            "Train Average Loss: 1.49\n",
            "Test Average loss: 1.70\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 107/300\n",
            "Train Average Loss: 1.49\n",
            "Test Average loss: 1.70\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 108/300\n",
            "Train Average Loss: 1.49\n",
            "Test Average loss: 1.70\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 109/300\n",
            "Train Average Loss: 1.49\n",
            "Test Average loss: 1.70\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 110/300\n",
            "Train Average Loss: 1.49\n",
            "Test Average loss: 1.70\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 111/300\n",
            "Train Average Loss: 1.49\n",
            "Test Average loss: 1.70\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 112/300\n",
            "Train Average Loss: 1.49\n",
            "Test Average loss: 1.70\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 113/300\n",
            "Train Average Loss: 1.49\n",
            "Test Average loss: 1.70\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 114/300\n",
            "Train Average Loss: 1.49\n",
            "Test Average loss: 1.70\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 115/300\n",
            "Train Average Loss: 1.48\n",
            "Test Average loss: 1.70\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 116/300\n",
            "Train Average Loss: 1.48\n",
            "Test Average loss: 1.71\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 117/300\n",
            "Train Average Loss: 1.48\n",
            "Test Average loss: 1.71\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 118/300\n",
            "Train Average Loss: 1.48\n",
            "Test Average loss: 1.71\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 119/300\n",
            "Train Average Loss: 1.48\n",
            "Test Average loss: 1.71\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 120/300\n",
            "Train Average Loss: 1.48\n",
            "Test Average loss: 1.72\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 121/300\n",
            "Train Average Loss: 1.48\n",
            "Test Average loss: 1.73\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 122/300\n",
            "Train Average Loss: 1.48\n",
            "Test Average loss: 1.73\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 123/300\n",
            "Train Average Loss: 1.48\n",
            "Test Average loss: 1.74\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 124/300\n",
            "Train Average Loss: 1.47\n",
            "Test Average loss: 1.74\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 125/300\n",
            "Train Average Loss: 1.47\n",
            "Test Average loss: 1.75\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 126/300\n",
            "Train Average Loss: 1.47\n",
            "Test Average loss: 1.76\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 127/300\n",
            "Train Average Loss: 1.47\n",
            "Test Average loss: 1.76\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 128/300\n",
            "Train Average Loss: 1.47\n",
            "Test Average loss: 1.77\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 129/300\n",
            "Train Average Loss: 1.47\n",
            "Test Average loss: 1.77\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 130/300\n",
            "Train Average Loss: 1.47\n",
            "Test Average loss: 1.78\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 131/300\n",
            "Train Average Loss: 1.47\n",
            "Test Average loss: 1.78\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 132/300\n",
            "Train Average Loss: 1.47\n",
            "Test Average loss: 1.78\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 133/300\n",
            "Train Average Loss: 1.47\n",
            "Test Average loss: 1.78\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 134/300\n",
            "Train Average Loss: 1.46\n",
            "Test Average loss: 1.77\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 135/300\n",
            "Train Average Loss: 1.46\n",
            "Test Average loss: 1.77\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 136/300\n",
            "Train Average Loss: 1.46\n",
            "Test Average loss: 1.77\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 137/300\n",
            "Train Average Loss: 1.46\n",
            "Test Average loss: 1.77\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 138/300\n",
            "Train Average Loss: 1.46\n",
            "Test Average loss: 1.77\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 139/300\n",
            "Train Average Loss: 1.46\n",
            "Test Average loss: 1.76\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 140/300\n",
            "Train Average Loss: 1.46\n",
            "Test Average loss: 1.76\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 141/300\n",
            "Train Average Loss: 1.46\n",
            "Test Average loss: 1.76\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 142/300\n",
            "Train Average Loss: 1.45\n",
            "Test Average loss: 1.77\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 143/300\n",
            "Train Average Loss: 1.45\n",
            "Test Average loss: 1.77\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 144/300\n",
            "Train Average Loss: 1.45\n",
            "Test Average loss: 1.77\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 145/300\n",
            "Train Average Loss: 1.45\n",
            "Test Average loss: 1.77\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 146/300\n",
            "Train Average Loss: 1.45\n",
            "Test Average loss: 1.77\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 147/300\n",
            "Train Average Loss: 1.45\n",
            "Test Average loss: 1.77\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 148/300\n",
            "Train Average Loss: 1.45\n",
            "Test Average loss: 1.76\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 149/300\n",
            "Train Average Loss: 1.45\n",
            "Test Average loss: 1.76\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 150/300\n",
            "Train Average Loss: 1.44\n",
            "Test Average loss: 1.75\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 151/300\n",
            "Train Average Loss: 1.44\n",
            "Test Average loss: 1.75\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 152/300\n",
            "Train Average Loss: 1.44\n",
            "Test Average loss: 1.75\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 153/300\n",
            "Train Average Loss: 1.44\n",
            "Test Average loss: 1.75\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 154/300\n",
            "Train Average Loss: 1.44\n",
            "Test Average loss: 1.75\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 155/300\n",
            "Train Average Loss: 1.44\n",
            "Test Average loss: 1.76\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 156/300\n",
            "Train Average Loss: 1.44\n",
            "Test Average loss: 1.76\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 157/300\n",
            "Train Average Loss: 1.43\n",
            "Test Average loss: 1.76\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 158/300\n",
            "Train Average Loss: 1.43\n",
            "Test Average loss: 1.76\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 159/300\n",
            "Train Average Loss: 1.43\n",
            "Test Average loss: 1.76\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 160/300\n",
            "Train Average Loss: 1.43\n",
            "Test Average loss: 1.77\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 161/300\n",
            "Train Average Loss: 1.43\n",
            "Test Average loss: 1.77\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 162/300\n",
            "Train Average Loss: 1.43\n",
            "Test Average loss: 1.78\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 163/300\n",
            "Train Average Loss: 1.43\n",
            "Test Average loss: 1.78\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 164/300\n",
            "Train Average Loss: 1.42\n",
            "Test Average loss: 1.79\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 165/300\n",
            "Train Average Loss: 1.42\n",
            "Test Average loss: 1.79\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 166/300\n",
            "Train Average Loss: 1.42\n",
            "Test Average loss: 1.79\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 167/300\n",
            "Train Average Loss: 1.42\n",
            "Test Average loss: 1.78\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 168/300\n",
            "Train Average Loss: 1.42\n",
            "Test Average loss: 1.78\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 169/300\n",
            "Train Average Loss: 1.42\n",
            "Test Average loss: 1.78\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 170/300\n",
            "Train Average Loss: 1.42\n",
            "Test Average loss: 1.78\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 171/300\n",
            "Train Average Loss: 1.41\n",
            "Test Average loss: 1.78\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 172/300\n",
            "Train Average Loss: 1.41\n",
            "Test Average loss: 1.78\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 173/300\n",
            "Train Average Loss: 1.41\n",
            "Test Average loss: 1.78\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 174/300\n",
            "Train Average Loss: 1.41\n",
            "Test Average loss: 1.78\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 175/300\n",
            "Train Average Loss: 1.41\n",
            "Test Average loss: 1.79\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 176/300\n",
            "Train Average Loss: 1.41\n",
            "Test Average loss: 1.79\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 177/300\n",
            "Train Average Loss: 1.41\n",
            "Test Average loss: 1.80\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 178/300\n",
            "Train Average Loss: 1.40\n",
            "Test Average loss: 1.81\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 179/300\n",
            "Train Average Loss: 1.40\n",
            "Test Average loss: 1.82\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 180/300\n",
            "Train Average Loss: 1.40\n",
            "Test Average loss: 1.82\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 181/300\n",
            "Train Average Loss: 1.40\n",
            "Test Average loss: 1.82\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 182/300\n",
            "Train Average Loss: 1.40\n",
            "Test Average loss: 1.82\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 183/300\n",
            "Train Average Loss: 1.40\n",
            "Test Average loss: 1.82\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 184/300\n",
            "Train Average Loss: 1.40\n",
            "Test Average loss: 1.81\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 185/300\n",
            "Train Average Loss: 1.40\n",
            "Test Average loss: 1.81\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 186/300\n",
            "Train Average Loss: 1.40\n",
            "Test Average loss: 1.81\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 187/300\n",
            "Train Average Loss: 1.40\n",
            "Test Average loss: 1.80\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 188/300\n",
            "Train Average Loss: 1.40\n",
            "Test Average loss: 1.80\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 189/300\n",
            "Train Average Loss: 1.40\n",
            "Test Average loss: 1.80\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 190/300\n",
            "Train Average Loss: 1.39\n",
            "Test Average loss: 1.80\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 191/300\n",
            "Train Average Loss: 1.39\n",
            "Test Average loss: 1.80\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 192/300\n",
            "Train Average Loss: 1.39\n",
            "Test Average loss: 1.81\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 193/300\n",
            "Train Average Loss: 1.39\n",
            "Test Average loss: 1.81\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 194/300\n",
            "Train Average Loss: 1.38\n",
            "Test Average loss: 1.81\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 195/300\n",
            "Train Average Loss: 1.38\n",
            "Test Average loss: 1.81\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 196/300\n",
            "Train Average Loss: 1.38\n",
            "Test Average loss: 1.81\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 197/300\n",
            "Train Average Loss: 1.38\n",
            "Test Average loss: 1.82\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 198/300\n",
            "Train Average Loss: 1.38\n",
            "Test Average loss: 1.82\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 199/300\n",
            "Train Average Loss: 1.38\n",
            "Test Average loss: 1.83\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 200/300\n",
            "Train Average Loss: 1.38\n",
            "Test Average loss: 1.83\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 201/300\n",
            "Train Average Loss: 1.37\n",
            "Test Average loss: 1.83\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 202/300\n",
            "Train Average Loss: 1.37\n",
            "Test Average loss: 1.83\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 203/300\n",
            "Train Average Loss: 1.37\n",
            "Test Average loss: 1.83\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 204/300\n",
            "Train Average Loss: 1.37\n",
            "Test Average loss: 1.83\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 205/300\n",
            "Train Average Loss: 1.37\n",
            "Test Average loss: 1.83\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 206/300\n",
            "Train Average Loss: 1.37\n",
            "Test Average loss: 1.83\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 207/300\n",
            "Train Average Loss: 1.37\n",
            "Test Average loss: 1.83\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 208/300\n",
            "Train Average Loss: 1.36\n",
            "Test Average loss: 1.82\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 209/300\n",
            "Train Average Loss: 1.36\n",
            "Test Average loss: 1.82\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 210/300\n",
            "Train Average Loss: 1.36\n",
            "Test Average loss: 1.81\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 211/300\n",
            "Train Average Loss: 1.36\n",
            "Test Average loss: 1.81\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 212/300\n",
            "Train Average Loss: 1.36\n",
            "Test Average loss: 1.80\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 213/300\n",
            "Train Average Loss: 1.36\n",
            "Test Average loss: 1.80\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 214/300\n",
            "Train Average Loss: 1.36\n",
            "Test Average loss: 1.80\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 215/300\n",
            "Train Average Loss: 1.36\n",
            "Test Average loss: 1.81\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 216/300\n",
            "Train Average Loss: 1.36\n",
            "Test Average loss: 1.81\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 217/300\n",
            "Train Average Loss: 1.36\n",
            "Test Average loss: 1.81\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 218/300\n",
            "Train Average Loss: 1.36\n",
            "Test Average loss: 1.82\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 219/300\n",
            "Train Average Loss: 1.35\n",
            "Test Average loss: 1.83\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 220/300\n",
            "Train Average Loss: 1.35\n",
            "Test Average loss: 1.84\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 221/300\n",
            "Train Average Loss: 1.35\n",
            "Test Average loss: 1.86\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 222/300\n",
            "Train Average Loss: 1.35\n",
            "Test Average loss: 1.87\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 223/300\n",
            "Train Average Loss: 1.35\n",
            "Test Average loss: 1.89\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 224/300\n",
            "Train Average Loss: 1.35\n",
            "Test Average loss: 1.90\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 225/300\n",
            "Train Average Loss: 1.35\n",
            "Test Average loss: 1.91\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 226/300\n",
            "Train Average Loss: 1.35\n",
            "Test Average loss: 1.92\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 227/300\n",
            "Train Average Loss: 1.34\n",
            "Test Average loss: 1.92\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 228/300\n",
            "Train Average Loss: 1.34\n",
            "Test Average loss: 1.91\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 229/300\n",
            "Train Average Loss: 1.34\n",
            "Test Average loss: 1.90\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 230/300\n",
            "Train Average Loss: 1.33\n",
            "Test Average loss: 1.89\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 231/300\n",
            "Train Average Loss: 1.33\n",
            "Test Average loss: 1.88\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 232/300\n",
            "Train Average Loss: 1.33\n",
            "Test Average loss: 1.87\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 233/300\n",
            "Train Average Loss: 1.33\n",
            "Test Average loss: 1.86\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 234/300\n",
            "Train Average Loss: 1.32\n",
            "Test Average loss: 1.86\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 235/300\n",
            "Train Average Loss: 1.32\n",
            "Test Average loss: 1.86\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 236/300\n",
            "Train Average Loss: 1.32\n",
            "Test Average loss: 1.85\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 237/300\n",
            "Train Average Loss: 1.32\n",
            "Test Average loss: 1.86\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 238/300\n",
            "Train Average Loss: 1.32\n",
            "Test Average loss: 1.86\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 239/300\n",
            "Train Average Loss: 1.32\n",
            "Test Average loss: 1.87\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 240/300\n",
            "Train Average Loss: 1.32\n",
            "Test Average loss: 1.88\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 241/300\n",
            "Train Average Loss: 1.31\n",
            "Test Average loss: 1.89\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 242/300\n",
            "Train Average Loss: 1.31\n",
            "Test Average loss: 1.89\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 243/300\n",
            "Train Average Loss: 1.31\n",
            "Test Average loss: 1.88\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 244/300\n",
            "Train Average Loss: 1.31\n",
            "Test Average loss: 1.88\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 245/300\n",
            "Train Average Loss: 1.31\n",
            "Test Average loss: 1.87\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 246/300\n",
            "Train Average Loss: 1.31\n",
            "Test Average loss: 1.87\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 247/300\n",
            "Train Average Loss: 1.30\n",
            "Test Average loss: 1.88\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 248/300\n",
            "Train Average Loss: 1.30\n",
            "Test Average loss: 1.88\n",
            "Test Accuracy: 7/30 (23.33%)\n",
            "\n",
            "Epoch: 249/300\n",
            "Train Average Loss: 1.30\n",
            "Test Average loss: 1.88\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 250/300\n",
            "Train Average Loss: 1.30\n",
            "Test Average loss: 1.87\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 251/300\n",
            "Train Average Loss: 1.30\n",
            "Test Average loss: 1.88\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 252/300\n",
            "Train Average Loss: 1.30\n",
            "Test Average loss: 1.88\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 253/300\n",
            "Train Average Loss: 1.29\n",
            "Test Average loss: 1.88\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 254/300\n",
            "Train Average Loss: 1.29\n",
            "Test Average loss: 1.88\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 255/300\n",
            "Train Average Loss: 1.29\n",
            "Test Average loss: 1.87\n",
            "Test Accuracy: 7/30 (23.33%)\n",
            "\n",
            "Epoch: 256/300\n",
            "Train Average Loss: 1.29\n",
            "Test Average loss: 1.86\n",
            "Test Accuracy: 7/30 (23.33%)\n",
            "\n",
            "Epoch: 257/300\n",
            "Train Average Loss: 1.29\n",
            "Test Average loss: 1.85\n",
            "Test Accuracy: 7/30 (23.33%)\n",
            "\n",
            "Epoch: 258/300\n",
            "Train Average Loss: 1.29\n",
            "Test Average loss: 1.84\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 259/300\n",
            "Train Average Loss: 1.29\n",
            "Test Average loss: 1.84\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 260/300\n",
            "Train Average Loss: 1.29\n",
            "Test Average loss: 1.83\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 261/300\n",
            "Train Average Loss: 1.29\n",
            "Test Average loss: 1.82\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 262/300\n",
            "Train Average Loss: 1.29\n",
            "Test Average loss: 1.82\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 263/300\n",
            "Train Average Loss: 1.28\n",
            "Test Average loss: 1.83\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 264/300\n",
            "Train Average Loss: 1.28\n",
            "Test Average loss: 1.84\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 265/300\n",
            "Train Average Loss: 1.27\n",
            "Test Average loss: 1.86\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 266/300\n",
            "Train Average Loss: 1.27\n",
            "Test Average loss: 1.87\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 267/300\n",
            "Train Average Loss: 1.27\n",
            "Test Average loss: 1.88\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 268/300\n",
            "Train Average Loss: 1.27\n",
            "Test Average loss: 1.90\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 269/300\n",
            "Train Average Loss: 1.27\n",
            "Test Average loss: 1.91\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 270/300\n",
            "Train Average Loss: 1.26\n",
            "Test Average loss: 1.92\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 271/300\n",
            "Train Average Loss: 1.27\n",
            "Test Average loss: 1.93\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 272/300\n",
            "Train Average Loss: 1.27\n",
            "Test Average loss: 1.93\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 273/300\n",
            "Train Average Loss: 1.26\n",
            "Test Average loss: 1.92\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 274/300\n",
            "Train Average Loss: 1.26\n",
            "Test Average loss: 1.91\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 275/300\n",
            "Train Average Loss: 1.25\n",
            "Test Average loss: 1.90\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 276/300\n",
            "Train Average Loss: 1.25\n",
            "Test Average loss: 1.89\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 277/300\n",
            "Train Average Loss: 1.25\n",
            "Test Average loss: 1.89\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 278/300\n",
            "Train Average Loss: 1.25\n",
            "Test Average loss: 1.88\n",
            "Test Accuracy: 7/30 (23.33%)\n",
            "\n",
            "Epoch: 279/300\n",
            "Train Average Loss: 1.25\n",
            "Test Average loss: 1.88\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 280/300\n",
            "Train Average Loss: 1.25\n",
            "Test Average loss: 1.89\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 281/300\n",
            "Train Average Loss: 1.25\n",
            "Test Average loss: 1.91\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 282/300\n",
            "Train Average Loss: 1.25\n",
            "Test Average loss: 1.92\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 283/300\n",
            "Train Average Loss: 1.25\n",
            "Test Average loss: 1.92\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 284/300\n",
            "Train Average Loss: 1.24\n",
            "Test Average loss: 1.92\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 285/300\n",
            "Train Average Loss: 1.24\n",
            "Test Average loss: 1.92\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 286/300\n",
            "Train Average Loss: 1.24\n",
            "Test Average loss: 1.92\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 287/300\n",
            "Train Average Loss: 1.24\n",
            "Test Average loss: 1.93\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 288/300\n",
            "Train Average Loss: 1.23\n",
            "Test Average loss: 1.93\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 289/300\n",
            "Train Average Loss: 1.23\n",
            "Test Average loss: 1.93\n",
            "Test Accuracy: 4/30 (13.33%)\n",
            "\n",
            "Epoch: 290/300\n",
            "Train Average Loss: 1.23\n",
            "Test Average loss: 1.93\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "\n",
            "Epoch: 291/300\n",
            "Train Average Loss: 1.23\n",
            "Test Average loss: 1.93\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 292/300\n",
            "Train Average Loss: 1.22\n",
            "Test Average loss: 1.93\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 293/300\n",
            "Train Average Loss: 1.22\n",
            "Test Average loss: 1.94\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 294/300\n",
            "Train Average Loss: 1.22\n",
            "Test Average loss: 1.94\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 295/300\n",
            "Train Average Loss: 1.22\n",
            "Test Average loss: 1.95\n",
            "Test Accuracy: 7/30 (23.33%)\n",
            "\n",
            "Epoch: 296/300\n",
            "Train Average Loss: 1.22\n",
            "Test Average loss: 1.95\n",
            "Test Accuracy: 7/30 (23.33%)\n",
            "\n",
            "Epoch: 297/300\n",
            "Train Average Loss: 1.22\n",
            "Test Average loss: 1.95\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 298/300\n",
            "Train Average Loss: 1.21\n",
            "Test Average loss: 1.93\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 299/300\n",
            "Train Average Loss: 1.22\n",
            "Test Average loss: 1.92\n",
            "Test Accuracy: 6/30 (20.00%)\n",
            "\n",
            "Epoch: 300/300\n",
            "Train Average Loss: 1.22\n",
            "Test Average loss: 1.91\n",
            "Test Accuracy: 5/30 (16.67%)\n",
            "Train Average loss: 1.22\n",
            "Train Accuracy: 42/70 (60.00%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training of Multilayer Perceptron on a random dataset"
      ],
      "metadata": {
        "id": "7kfMPP29PjM4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this we will use the Mulitlayer Perceptron defined in question 4 and train it on a random dataset."
      ],
      "metadata": {
        "id": "gIuWBG8HS9rh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Please DO NOT modify this cell.\n",
        "\n",
        "import os\n",
        "import os.path as osp\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def set_seed(seed: int):\n",
        "\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)"
      ],
      "metadata": {
        "id": "YQF7MZt0P1a8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Please DO NOT modify this cell.\n",
        "\n",
        "num_features = 10\n",
        "classes = [0, 1, 2, 3, 4]\n",
        "num_classes = len(classes)\n",
        "\n",
        "num_samples = 100\n",
        "num_train = 70\n",
        "num_test = num_samples - num_train"
      ],
      "metadata": {
        "id": "wjcnZEPBP4We"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Please DO NOT modify this cell.\n",
        "# We are creating a random feature set and a random label set.\n",
        "# The features and labels have no semantic meaning and might as well be garbage.\n",
        "\n",
        "set_seed(2022)\n",
        "\n",
        "features = np.random.random_sample((num_samples, num_features))\n",
        "labels = np.random.choice(classes, size = num_samples)\n",
        "\n",
        "# Train-test split\n",
        "x_train = features[:num_train]\n",
        "x_test = features[num_train:num_samples]\n",
        "\n",
        "x_train = torch.Tensor(x_train)\n",
        "x_test = torch.Tensor(x_test)\n",
        "\n",
        "y_train = labels[:num_train]\n",
        "y_test = labels[num_train:num_samples]\n",
        "\n",
        "y_train = torch.LongTensor(y_train)\n",
        "y_test = torch.LongTensor(y_test)"
      ],
      "metadata": {
        "id": "nD5QxcLZP7Sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Please DO NOT modify this cell.\n",
        "\n",
        "print(f\"Train features: {x_train.shape}\")\n",
        "print(f\"Test features: {x_test.shape}\")\n",
        "\n",
        "print(f\"Train labels: {y_train.shape}\")\n",
        "print(f\"Train labels: {y_test.shape}\")\n"
      ],
      "metadata": {
        "id": "fLjE4V28P9xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create train and test TensorDatasets from the respective numpy arrays"
      ],
      "metadata": {
        "id": "YW7PbFdoTMLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train and test TensorDatasets from the respective numpy arrays\n",
        "\n",
        "#### YOUR CODE STARTS HERE ####\n",
        "\n",
        "train_dataset = ___\n",
        "test_dataset = ___\n",
        "\n",
        "#### YOUR CODE ENDS HERE ####"
      ],
      "metadata": {
        "id": "Ch3_WtqPQAaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create dataloaders using the datasets created in the previous cell."
      ],
      "metadata": {
        "id": "I_nn_5UFTSPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataloaders using the datasets created in the previous cell.\n",
        "# Use a batch size of 64\n",
        "\n",
        "#### YOUR CODE STARTS HERE ####\n",
        "\n",
        "batch_size = ___\n",
        "\n",
        "train_loader = ___\n",
        "test_loader = ___\n",
        "\n",
        "#### YOUR CODE ENDS HERE ####"
      ],
      "metadata": {
        "id": "D3BgZXDjQDMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training function"
      ],
      "metadata": {
        "id": "LNRJDdcwQHxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "        #### YOUR CODE STARTS HERE ####\n",
        "\n",
        "        # send the data, target to the device\n",
        "        data = ___\n",
        "        target = ___\n",
        "\n",
        "        # flush out the gradients stored in optimizer\n",
        "        ___\n",
        "\n",
        "        # pass the batch to the model and assign the output to variable named y_pred\n",
        "        output = ___\n",
        "\n",
        "        # calculate the loss (use CrossEntropyLoss in pytorch)\n",
        "        loss = ___\n",
        "\n",
        "        # do a backward pass\n",
        "        ___\n",
        "\n",
        "        # update the weights\n",
        "        ___\n",
        "\n",
        "        #### YOUR CODE ENDS HERE ####\n",
        "\n",
        "        # Store loss\n",
        "        epoch_loss += loss.item() * data.shape[0]\n",
        "\n",
        "    print(f\"Train Average Loss: {epoch_loss/len(train_loader.dataset):.2f}\")"
      ],
      "metadata": {
        "id": "JQ6_PT9WQKL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test function"
      ],
      "metadata": {
        "id": "YuDmvAKNQNEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, device, test_loader, criterion, mode):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            #### YOUR CODE STARTS HERE ####\n",
        "\n",
        "            # send data, target to the device\n",
        "            data = ___\n",
        "            target = ___\n",
        "\n",
        "            # pass the image to the model and assign the output to variable named output\n",
        "            output = ___\n",
        "            #### YOUR CODE ENDS HERE ####\n",
        "\n",
        "            test_loss += criterion(output, target).item() * data.shape[0]  # sum up batch loss\n",
        "            pred = output.argmax(dim = 1, keepdim = True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_acc = 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "    print(f\"{mode} Average loss: {test_loss:.2f}\")\n",
        "    print(f\"{mode} Accuracy: {correct}/{len(test_loader.dataset)} ({test_acc:.2f}%)\")"
      ],
      "metadata": {
        "id": "ZBY3D0IsQOZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(2022)\n",
        "\n",
        "num_epochs = 300\n",
        "\n",
        "#### YOUR CODE STARTS HERE ####\n",
        "\n",
        "# check availability of GPU and set the device accordingly\n",
        "device = ___\n",
        "\n",
        "# Initialize MLP model\n",
        "model = ___\n",
        "\n",
        "# Define Adam Optimizer with a learning rate of 0.001\n",
        "optimizer = ___\n",
        "\n",
        "# Define CrossEntropyLoss as the criterion\n",
        "criterion = ___\n",
        "\n",
        "#### YOUR CODE ENDS HERE ####\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    print(f\"\\nEpoch: {epoch}/{num_epochs}\")\n",
        "\n",
        "    train(model, device, train_loader, optimizer, criterion, epoch)\n",
        "    test(model, device, test_loader, criterion, mode = \"Test\")"
      ],
      "metadata": {
        "id": "aZ2P3nG2QRme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVQZOy5M8g3O"
      },
      "outputs": [],
      "source": [
        "test(model, device, train_loader, criterion, mode = \"Train\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maYYAzU28g3N"
      },
      "source": [
        "### Question 5\n",
        "\n",
        "Report the final train accuracy (If you are not getting the exact number shown in\n",
        "options, please report the closest number).\n",
        "\n",
        "a. 100%\n",
        "\n",
        "b. 53%\n",
        "\n",
        "c. 61%\n",
        "\n",
        "d. 79%\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#61%"
      ],
      "metadata": {
        "id": "2wiHcu8NKgv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXEEd8YP8g3S"
      },
      "outputs": [],
      "source": [
        "test(model, device, test_loader, criterion, mode = \"Test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV3DSN3v0NBN"
      },
      "source": [
        "### Question 6\n",
        "\n",
        "Report the final test accuracy (If you are not getting the exact number shown in\n",
        "options, please report the closest number).\n",
        "\n",
        "a. 30%\n",
        "\n",
        "b. 40%\n",
        "\n",
        "c. 15%\n",
        "\n",
        "d. 25%\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 15%"
      ],
      "metadata": {
        "id": "vVuu208NKtfR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}